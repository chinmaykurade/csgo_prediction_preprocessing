{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "#models:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,\\\n",
    "GradientBoostingClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "##\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read all the datasets\n",
    "def read_all(template,start,end):\n",
    "    frames = [ pd.read_json(f).fillna(0) for f in [template.format(i) for i in range(start,end)] ]\n",
    "    X = pd.concat(frames, ignore_index = True,sort = True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"datasets/dataset_finalized/dataset_{:02}.json\"\n",
    "df = read_all(template,0,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122074 entries, 0 to 122073\n",
      "Columns: 185 entries, Ak47_ct to t_leads\n",
      "dtypes: float64(11), int64(174)\n",
      "memory usage: 172.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colwep = ['Ak47_ct', 'Ak47_t', 'Aug_ct', 'Aug_t', 'Awp_ct', 'Awp_t', 'C4_t', 'Cz75Auto_ct',\\\n",
    "          'Cz75Auto_t', 'Deagle_ct', 'Deagle_t', 'DecoyGrenade_ct', 'DecoyGrenade_t', 'Flashbang_ct',\\\n",
    "          'Flashbang_t', 'Glock_ct', 'Glock_t', 'HeGrenade_ct', 'HeGrenade_t', 'M4a4_ct', 'M4a4_t',\\\n",
    "          'MolotovIncendiaryGrenade_ct', 'MolotovIncendiaryGrenade_t', 'Mp9_ct', 'Mp9_t', 'P2000_ct',\\\n",
    "          'P2000_t', 'P250_ct', 'P250_t', 'Sg553_ct', 'Sg553_t', 'SmokeGrenade_ct', 'SmokeGrenade_t',\\\n",
    "          'UspS_ct', 'UspS_t','other_heavy_ct', 'other_heavy_t', 'other_pistols_ct', \\\n",
    "          'other_pistols_t', 'other_rifles_ct', 'other_rifles_t', 'other_smgs_ct', 'other_smgs_t']\n",
    "\n",
    "# colwep = ['Ak47_ct', 'Ak47_t', 'Aug_ct', 'Aug_t', 'Awp_ct', 'Awp_t', 'C4_t',\\\n",
    "#           'Deagle_ct', 'Deagle_t', 'Flashbang_ct',\\\n",
    "#           'Flashbang_t', 'Glock_ct', 'Glock_t', 'HeGrenade_ct', 'HeGrenade_t', 'M4a4_ct', 'M4a4_t',\\\n",
    "#           'MolotovIancendiaryGrenade_ct', 'MolotovIncendiaryGrenade_t', 'P2000_ct',\\\n",
    "#           'P2000_t', 'P250_ct', 'P250_t', 'Sg553_ct', 'Sg553_t', 'SmokeGrenade_ct', 'SmokeGrenade_t',\\\n",
    "#           'UspS_ct', 'UspS_t']\n",
    "\n",
    "colpla = ['alive_players_ct', 'alive_players_t', 'armor_ct1_Bin_Code', 'armor_ct2_Bin_Code',\\\n",
    "          'armor_ct3_Bin_Code', 'armor_ct4_Bin_Code', 'armor_ct5_Bin_Code', 'armor_ct_Bin_Code',\\\n",
    "          'armor_t1_Bin_Code', 'armor_t2_Bin_Code', 'armor_t3_Bin_Code', 'armor_t4_Bin_Code',\\\n",
    "          'armor_t5_Bin_Code', 'armor_t_Bin_Code','defuse_kit_ct1', 'defuse_kit_ct2',\\\n",
    "          'defuse_kit_ct3', 'defuse_kit_ct4', 'defuse_kit_ct5','defuse_kit_ct', \\\n",
    "          'has_helmet_ct1', 'has_helmet_ct2', 'has_helmet_ct3', 'has_helmet_ct4', 'has_helmet_ct5', \\\n",
    "          'has_helmet_ct','has_helmet_t1', 'has_helmet_t2', 'has_helmet_t3', 'has_helmet_t4',\\\n",
    "          'has_helmet_t5','has_helmet_t', 'health_ct1_Bin_Code', 'health_ct2_Bin_Code', \\\n",
    "          'health_ct3_Bin_Code', 'health_ct4_Bin_Code', 'health_ct5_Bin_Code','health_ct_Bin_Code',\\\n",
    "          'health_t1_Bin_Code', 'health_t2_Bin_Code', 'health_t3_Bin_Code', 'health_t4_Bin_Code',\\\n",
    "          'health_t5_Bin_Code','health_t_Bin_Code','money_ct1_Bin_Code', 'money_ct2_Bin_Code',\\\n",
    "          'money_ct3_Bin_Code', 'money_ct4_Bin_Code', 'money_ct5_Bin_Code', \\\n",
    "          'money_ct_Bin_Code', 'money_t1_Bin_Code', 'money_t2_Bin_Code', 'money_t3_Bin_Code', \\\n",
    "          'money_t4_Bin_Code', 'money_t5_Bin_Code', 'money_t_Bin_Code']\n",
    "\n",
    "colsta = ['current_score_ct', 'current_score_t','t_leads','round_status_BombPlanted',\\\n",
    "          'round_status_FreezeTime', 'round_status_Normal', 'round_status_time_left']\n",
    "\n",
    "colkill = ['kwct_Ak47', 'kwct_Aug', 'kwct_Awp', 'kwct_C4', 'kwct_Cz75Auto', 'kwct_Deagle',\\\n",
    "           'kwct_Flashbang', 'kwct_Glock', 'kwct_HeGrenade', 'kwct_Knife', 'kwct_M4a4',\\\n",
    "           'kwct_MolotovIncendiaryGrenade', 'kwct_Mp9', 'kwct_P2000', 'kwct_P250', 'kwct_Sg553',\\\n",
    "           'kwct_SmokeGrenade', 'kwct_UspS', 'kwct_other_heavy', 'kwct_other_pistols',\\\n",
    "           'kwct_other_rifles', 'kwct_other_smgs', 'kwct_other_utils', 'kwct_other_world', 'kwt_Ak47',\\\n",
    "           'kwt_Aug', 'kwt_Awp', 'kwt_C4', 'kwt_Cz75Auto', 'kwt_Deagle', 'kwt_Flashbang', 'kwt_Glock',\\\n",
    "           'kwt_HeGrenade', 'kwt_Knife', 'kwt_M4a4', 'kwt_MolotovIncendiaryGrenade', 'kwt_Mp9',\\\n",
    "           'kwt_P2000', 'kwt_P250', 'kwt_Sg553', 'kwt_SmokeGrenade', 'kwt_UspS', 'kwt_other_heavy',\\\n",
    "           'kwt_other_pistols', 'kwt_other_rifles', 'kwt_other_smgs', 'kwt_other_utils',\\\n",
    "           'kwt_other_world']\n",
    "\n",
    "colmap = ['map_de_dust2', 'map_de_inferno', 'map_de_mirage', 'map_de_nuke', 'map_de_overpass',\\\n",
    "          'map_de_train', 'map_de_vertigo','map_de_cache']\n",
    "\n",
    "colpos = ['pos_bs_ct1', 'pos_bs_ct2', 'pos_bs_ct3', 'pos_bs_ct4', 'pos_bs_ct5', 'pos_bs_t1',\\\n",
    "          'pos_bs_t2', 'pos_bs_t3', 'pos_bs_t4', 'pos_bs_t5']\n",
    "\n",
    "# colpos = ['pos_bs_ct1', 'pos_bs_ct2', 'pos_bs_ct3', 'pos_bs_ct4', 'pos_bs_ct5', 'pos_bs_t1',\\\n",
    "#           'pos_bs_t2', 'pos_bs_t3', 'pos_bs_t4', 'pos_bs_t5', 'pr_ct1','pr_ct2', 'pr_ct3',\\\n",
    "#           'pr_ct4', 'pr_ct5', 'pr_t1', 'pr_t2', 'pr_t3', 'pr_t4', 'pr_t5']\n",
    "\n",
    "cols = colpla+colmap+colwep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all = df['round_winner_t']\n",
    "X_all = df.drop(columns='round_winner_t',axis=1)[cols]\n",
    "X_all = StandardScaler().fit_transform(X_all) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122074, 107)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122074,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,X_t,Y_t,degree):\n",
    "    pr = PolynomialFeatures(degree=degree,include_bias=True)\n",
    "    X_p = pr.fit_transform(X_t)\n",
    "    model.fit(X_p,Y_t)\n",
    "    pred_train = model.predict(X_p)\n",
    "    \n",
    "    return pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,X_t,degree):\n",
    "    pr = PolynomialFeatures(degree=degree,include_bias=True)\n",
    "    X_p = pr.fit_transform(X_t)\n",
    "    \n",
    "    return model.predict(X_p)\n",
    "\n",
    "def get_mse(model,Y_train,pred_train,Y_test,pred_test):\n",
    "    train_mse = mean_squared_error(Y_train, pred_train)\n",
    "    test_mse = mean_squared_error(Y_test, pred_test)\n",
    "    print(\"Training MSE = {}\".format(train_mse))\n",
    "    print(\"Test MSE = {}\".format(test_mse))\n",
    "\n",
    "def train_test(model,X_train,Y_train,X_test,Y_test,degree):\n",
    "    pred_train = train_model(model,X_train,Y_train,degree)\n",
    "    pred_test = test_model(model,X_test,degree)\n",
    "    get_mse(model,Y_train,pred_train,Y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "    LinearRegression(),\n",
    "    LogisticRegression(solver='sag',verbose=1),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(max_iter=500,hidden_layer_sizes=(100,10,2,)),\n",
    "    GradientBoostingClassifier(),\n",
    "# #     VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)]),\n",
    "    BaggingClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "#     SVC(probability=True),\n",
    "#     KNeighborsClassifier(n_neighbors = 3),\n",
    "    RandomForestClassifier(n_estimators = 200,verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the classification on LinearRegression\n",
      "Running the classification on LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 51 epochs took 8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 43 epochs took 10 seconds\n",
      "Running the classification on GaussianNB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the classification on MLPClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the classification on GradientBoostingClassifier\n",
      "Running the classification on BaggingClassifier\n",
      "Running the classification on ExtraTreesClassifier\n",
      "Running the classification on DecisionTreeClassifier\n",
      "Running the classification on RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   51.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.995707</td>\n",
       "      <td>0.854639</td>\n",
       "      <td>0</td>\n",
       "      <td>34.2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.995707</td>\n",
       "      <td>0.85087</td>\n",
       "      <td>0</td>\n",
       "      <td>52.3161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.987985</td>\n",
       "      <td>0.815605</td>\n",
       "      <td>0</td>\n",
       "      <td>24.5424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.995707</td>\n",
       "      <td>0.778906</td>\n",
       "      <td>0</td>\n",
       "      <td>3.63029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.872055</td>\n",
       "      <td>0.768913</td>\n",
       "      <td>0</td>\n",
       "      <td>413.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>0.715526</td>\n",
       "      <td>0.71452</td>\n",
       "      <td>0</td>\n",
       "      <td>79.9161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.707662</td>\n",
       "      <td>0.709482</td>\n",
       "      <td>0</td>\n",
       "      <td>8.11335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.689979</td>\n",
       "      <td>0.690518</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.260083</td>\n",
       "      <td>0.258506</td>\n",
       "      <td>0</td>\n",
       "      <td>1.47905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MLA Name  \\\n",
       "6        ExtraTreesClassifier   \n",
       "8      RandomForestClassifier   \n",
       "5           BaggingClassifier   \n",
       "7      DecisionTreeClassifier   \n",
       "3               MLPClassifier   \n",
       "4  GradientBoostingClassifier   \n",
       "1          LogisticRegression   \n",
       "2                  GaussianNB   \n",
       "0            LinearRegression   \n",
       "\n",
       "                                      MLA Parameters MLA Train Accuracy Mean  \\\n",
       "6  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...                0.995707   \n",
       "8  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...                0.995707   \n",
       "5  {'base_estimator': None, 'bootstrap': True, 'b...                0.987985   \n",
       "7  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                0.995707   \n",
       "3  {'activation': 'relu', 'alpha': 0.0001, 'batch...                0.872055   \n",
       "4  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...                0.715526   \n",
       "1  {'C': 1.0, 'class_weight': None, 'dual': False...                0.707662   \n",
       "2           {'priors': None, 'var_smoothing': 1e-09}                0.689979   \n",
       "0  {'copy_X': True, 'fit_intercept': True, 'n_job...                0.260083   \n",
       "\n",
       "  MLA Test Accuracy Mean MLA Test Accuracy 3*STD  MLA Time  \n",
       "6               0.854639                       0   34.2663  \n",
       "8                0.85087                       0   52.3161  \n",
       "5               0.815605                       0   24.5424  \n",
       "7               0.778906                       0   3.63029  \n",
       "3               0.768913                       0   413.218  \n",
       "4                0.71452                       0   79.9161  \n",
       "1               0.709482                       0   8.11335  \n",
       "2               0.690518                       0  0.541551  \n",
       "0               0.258506                       0   1.47905  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "#note: this is an alternative to train_test_split\n",
    "cv_split = ShuffleSplit(n_splits = 1, test_size = .20, train_size = .75, \\\n",
    "                                                random_state = 0 )\n",
    "                    # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "\n",
    "#create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', \\\n",
    "               'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "#create table to compare MLA predictions\n",
    "MLA_predict = Y_all.copy()\n",
    "\n",
    "#index through MLA and save performance to table\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    print(\"Running the classification on %s\" %(MLA_name))\n",
    "    \n",
    "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    cv_results = cross_validate(alg, X_all, Y_all, cv  = cv_split,return_train_score=True)\n",
    "\n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
    "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, \n",
    "    #should statistically capture 99.7% of the subsets\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   \n",
    "    #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "    #save MLA predictions - see section 6 for usage\n",
    "    alg.fit(X_all, Y_all)\n",
    "    MLA_predict[MLA_name] = alg.predict(X_all)\n",
    "    \n",
    "    row_index+=1\n",
    "\n",
    "    \n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "MLA_compare\n",
    "#MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 1\n",
    "# model = RandomForestClassifier(n_estimators = 100,verbose=1)\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "# model = MLPClassifier(verbose=1,max_iter=300,hidden_layer_sizes=(150,100,10,2,))\n",
    "# model = SVC(probability=True,verbose=1)\n",
    "# model = ExtraTreesClassifier()\n",
    "train_test(model,X_train,Y_train,X_test,Y_test,degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
